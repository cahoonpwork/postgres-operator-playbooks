[
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Crunchy Data PostgreSQL Operator Playbooks The Crunchy Data PostgreSQL Operator Playbooks contain Ansible roles for installing and managing the Crunchy Data PostgreSQL Operator.\nFeatures The playbooks provided allow users to:\n install PostgreSQL Operator on Kubernetes and OpenShift install PostgreSQL from a Linux, Mac or Windows(Cygwin) host generate TLS certificates required by the PostgreSQL Operator configure PostgreSQL Operator settings from a single inventory file support a variety of deployment models  Resources  Ansible Crunchy Data Crunchy Data PostgreSQL Operator Documentation Crunchy Data PostgreSQL Operator Project  "
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/prereq/",
	"title": "Prerequiste",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/uninstall/",
	"title": "Uninstall",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/prereq/prerequisites/",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": " Prerequisites The following is required prior to installing PostgreSQL Operator using Ansible:\n Ansible 2.4.6+ Kubernetes v1.11+ or OpenShift v3.09+ kubectl or oc configured to communicate with Kubernetes postgres-operator-playbooks source code checked out for the target version  Configuring the Inventory File The inventory file included with the PostgreSQL Operator Playbooks allows installers to configure how the operator will function when deployed into Kubernetes. This file should contain all configurable variables the playbooks offer.\nThe following are the variables available for configuration:\n   Name Default Description     archive_mode true Set to true enable archive logging on all newly created clusters.   archive_timeout 60 Set to a value in seconds to configure the timeout threshold for archiving.   auto_failover_replace_replica false Set to true to replace promoted replicas during failovers with a new replica on all newly created clusters.   auto_failover_sleep_secs 9 Set to a value in seconds to configure the sleep time before initiating a failover on all newly created clusters.   auto_failover false Set to true enable auto failover capabilities on all newly created clusters.   backrest false Set to true enable pgBackRest capabilities on all newly created clusters.   backrest_aws_s3_key  Set to configure the key used by pgBackRest to authenticate with Amazon Web Service S3 for backups and restoration in S3.   backrest_aws_s3_secret  Set to configure the secret used by pgBackRest to authenticate with Amazon Web Service S3 for backups and restoration in S3.   backrest_aws_s3_bucket  Set to configure the bucket used by pgBackRest with Amazon Web Service S3 for backups and restoration in S3.   backrest_aws_s3_endpoint  Set to configure the endpoint used by pgBackRest with Amazon Web Service S3 for backups and restoration in S3.   backrest_aws_s3_region  Set to configure the region used by pgBackRest with Amazon Web Service S3 for backups and restoration in S3.   backrest_storage storage1 Set to configure which storage definition to use when creating volumes used by pgBackRest on all newly created clusters.   badger false Set to true enable pgBadger capabilities on all newly created clusters.   ccp_image_prefix crunchydata Configures the image prefix used when creating containers from Crunchy Container Suite.   ccp_image_tag  Configures the image tag (version) used when creating containers from Crunchy Container Suite.   cleanup false Set to configure the playbooks to delete all objects when deprovisioning Operator. Note: this will delete all objects related to the Operator (including clusters provisioned).   crunchy_debug false Set to configure Operator to use debugging mode. Note: this can cause sensitive data such as passwords to appear in Operator logs.   db_name userdb Set to a value to configure the default database name on all newly created clusters.   db_password_age_days 60 Set to a value in days to configure the expiration age on PostgreSQL role passwords on all newly created clusters.   db_password_length 20 Set to configure the size of passwords generated by the operator on all newly created roles.   db_port 5432 Set to configure the default port used on all newly created clusters.   db_replicas 1 Set to configure the amount of replicas provisioned on all newly created clusters.   db_user testuser Set to configure the username of the dedicated user account on all newly created clusters.   grafana_admin_username admin Set to configure the login username for the Grafana administrator.   grafana_admin_password  Set to configure the login password for the Grafana administrator.   grafana_install true Set to true to install Crunchy Grafana to visualize metrics.   grafana_storage_access_mode  Set to the access mode used by the configured storage class for Grafana persistent volumes.   grafana_storage_class_name  Set to the name of the storage class used when creating Grafana persistent volumes.   grafana_volume_size  Set to the size of persistent volume to create for Grafana.   kubernetes_context  When deploying to Kubernetes, set to configure the context name of the kubeconfig to be used for authentication.   log_statement none Set to none, ddl, mod, or all to configure the statements that will be logged in PostgreSQL\u0026rsquo;s logs on all newly created clusters.   metrics false Set to true enable performance metrics on all newly created clusters.   metrics_namespace metrics Configures the target namespace when deploying Grafana and/or Prometheus   openshift_host  When deploying to OpenShift, set to configure the hostname of the OpenShift cluster to connect to.   openshift_password  When deploying to OpenShift, set to configure the password used for login.   openshift_skip_tls_verify  When deploying to Openshift, set to ignore the integrity of TLS certificates for the OpenShift cluster.   openshift_token  When deploying to OpenShift, set to configure the token used for login (when not using username/password authentication).   openshift_user  When deploying to OpenShift, set to configure the username used for login.   pgo_client_install true Configures the playbooks to install the pgo client if set to true.   pgo_image_prefix crunchydata Configures the image prefix used when creating containers for the Crunchy PostgreSQL Operator (apiserver, operator, scheduler..etc).   pgo_image_tag  Configures the image tag used when creating containers for the Crunchy PostgreSQL Operator (apiserver, operator, scheduler..etc)   pgo_namespace  Set to configure the namespace where Operator will be deployed.   pgo_password  Configures the pgo administrator password.   pgo_tls_no_verify  Set to configure Operator to verify TLS certificates.   pgo_username admin Configures the pgo administrator username.   primary_storage storage2 Set to configure which storage definition to use when creating volumes used by PostgreSQL primaries on all newly created clusters.   prometheus_install true Set to true to install Crunchy Prometheus timeseries database.   prometheus_storage_access_mode  Set to the access mode used by the configured storage class for Prometheus persistent volumes.   prometheus_storage_class_name  Set to the name of the storage class used when creating Prometheus persistent volumes.   grafana_volume_size  Set to the size of persistent volume to create for Grafana.   replica_storage storage3 Set to configure which storage definition to use when creating volumes used by PostgreSQL replicas on all newly created clusters.   scheduler_timeout 3600 Set to a value in seconds to configure the pgo-scheduler timeout threshold when waiting for schedules to complete.   service_type ClusterIP Set to configure the type of Kubernetes service provisioned on all newly created clusters.   storage\u0026lt;ID\u0026gt;_access_mode  Set to configure the access mode of the volumes created when using this storage definition.   storage\u0026lt;ID\u0026gt;_class  Set to configure the storage class name used when creating dynamic volumes.   storage\u0026lt;ID\u0026gt;_fs_group  Set to configure any filesystem groups that should be added to security contexts on newly created clusters.   storage\u0026lt;ID\u0026gt;_size  Set to configure the size of the volumes created when using this storage definition.   storage\u0026lt;ID\u0026gt;_supplemental_groups  Set to configure any supplemental groups that should be added to security contexts on newly created clusters.   storage\u0026lt;ID\u0026gt;_type  Set to either create or dynamic to configure the operator to create persistent volumes or have them created dynamically by a storage class.   target_namespaces  Set to a comma delimited string of all the namespaces Operator will manage.   xlog_storage storage1 Set to configure which storage definition to use when creating volumes used to store Write Ahead Logs (WAL) archives on all newly created clusters.    Storage Kubernetes and OpenShift offer support for a variety of storage types. The Crunchy PostgreSQL Operator must be configured to utilize the storage options available by configuring the storage options included in the inventory file.\nAt this time the Crunchy PostgreSQL Operator Playbooks only support storage classes.\n Considerations for Multi-Zone Cloud Environments When using the Operator in a Kubernetes cluster consisting of nodes that span multiple zones, special consideration must betaken to ensure all pods and the volumes they require are scheduled and provisioned within the same zone. Specifically, being that a pod is unable mount a volume that is located in another zone, any volumes that are dynamically provisioned must be provisioned in a topology-aware manner according to the specific scheduling requirements for the pod. For instance, this means ensuring that the volume containing the database files for the primary database in a new PostgreSQL cluster is provisioned in the same zone as the node containing the PostgreSQL primary pod that will be using it.\nFor instructions on setting up storage classes for multi-zone environments, see the PostgreSQL Operator Documentation.\nExamples The following are examples on configuring the storage variables for different types of storage classes.\nGeneric Storage Class To setup storage1 to use a the storage class fast\nstorage1_access_mode=\u0026#39;ReadWriteOnce\u0026#39; storage1_size=\u0026#39;10G\u0026#39; storage1_type=\u0026#39;dynamic\u0026#39; storage1_class=\u0026#39;fast\u0026#39; To assign this storage definition to all primary pods created by the Operator, we can configure the primary_storage=storage1 variable in the inventory file.\nGKE The storage class provided by Google Kubernetes Environment (GKE) can be configured to be used by the Operator by setting the following variables in the inventory file:\nstorage1_access_mode=\u0026#39;ReadWriteOnce\u0026#39; storage1_size=\u0026#39;10G\u0026#39; storage1_type=\u0026#39;dynamic\u0026#39; storage1_class=\u0026#39;standard\u0026#39; storage1_fs_group=26 To assign this storage definition to all primary pods created by the Operator, we can configure the primary_storage=storage1 variable in the inventory file.\nTo utitlize mutli-zone deployments, see Considerations for Multi-Zone Cloud Environments above.\n Understanding pgo_namespace \u0026amp; target_namespaces The Crunchy PostgreSQL Operator can be configured to be deployed and manage a single namespace or manage several namespaces. The following are examples of different types of deployment models configurable in the inventory file.\nSingle Namespace To deploy the Crunchy PostgreSQL Operator to work with a single namespace (in this example our namespace is named pgo), configure the following inventory settings:\npgo_namespace=\u0026#39;pgo\u0026#39; target_namespaces=\u0026#39;pgo\u0026#39; Multiple Namespaces To deploy the Crunchy PostgreSQL Operator to work with multiple namespaces (in this example our namespaces are named pgo, pgouser1 and pgouser2), configure the following inventory settings:\npgo_namespace=\u0026#39;pgo\u0026#39; target_namespaces=\u0026#39;pgouser1,pgouser2\u0026#39; Deploying Multiple Operators The 4.0 release of the Crunchy PostgreSQL Operator allows for multiple operator deployments in the same cluster.\nTo install the Crunchy PostgreSQL Operator to multiple namespaces, it\u0026rsquo;s recommended to have an inventory file for each deployment of the operator.\nFor each operator deployment the following inventory variables should be configured uniquely for each install.\nFor example, operator could be deployed twice by changing the pgo_namespace and target_namespaces for those deployments:\nInventory A would deploy operator to the pgo namespace and it would manage the pgo target namespace.\n# Inventory A pgo_namespace=\u0026#39;pgo\u0026#39; target_namespaces=\u0026#39;pgo\u0026#39; ... Inventory B would deploy operator to the pgo2 namespace and it would manage the pgo2 and pgo3 target namespaces.\n# Inventory B pgo_namespace=\u0026#39;pgo2\u0026#39; target_namespaces=\u0026#39;pgo2,pgo3\u0026#39; ... Each install of the operator will create a corresponding directory in $HOME/.pgo/\u0026lt;PGO NAMESPACE\u0026gt; which will contain the TLS and pgouser client credentials.\nDeploying Grafana and Prometheus PostgreSQL clusters created by the operator can be configured to create additional containers for collecting metrics.\nThese metrics are very useful for understanding the overall health and performance of PostgreSQL database deployments over time. The collectors included by the operator are:\n Node Exporter - Host metrics where the PostgreSQL containers are running PostgreSQL Exporter - PostgreSQL metrics  The operator, however, does not install the neccessary timeseries database (Prometheus) for storing the collected metrics or the front end visualization (Grafana) of those metrics.\nIncluded in these playbooks are roles for deploying Granfana and/or Prometheus. See the inventory file for options to install the metrics stack.\nAt this time the Crunchy PostgreSQL Operator Playbooks only support storage classes.\n "
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/installation/installing-ansible/",
	"title": "Installing Ansible",
	"tags": [],
	"description": "",
	"content": " Installing Ansible on Linux or MacOS To install Ansible on Linux or MacOS, see the official documentation provided by Ansible.\nInstalling Ansible on Windows (Cygwin) The following instructions will install Cygwin with Ansible.\nFirst the Cygwin installer must be downloaded. This should only be downloaded and not executed.\nNext, open a Windows Command Prompt using the following:\n [WINDOWS KEY] + R Type into the run prompt cmd and press enter  With the Windows Command Prompt open, paste the following command into the prompt:\n%HOMEPATH%\\Downloads\\setup-x86_64.exe ^ --site http://cygwin.mirror.constant.com ^ --quiet-mode ^ --arch x86 ^ --verbose ^ --packages binutils,curl,cygwin32-gcc-g++,gcc-g++,git,gmp,libffi-devel,libgmp-devel,libsodium-devel,make,nano,openssh,libcrypt-devel,openssl,openssl-devel,python36,python36-pip,python36-setuptools,python36-devel,python36-crypto,python3-cryptography,vim,unzip,wget  Setting Up Cygwin Environment Once the installation is complete navigate to the desktop and double click the Cygwin shortcut icon.\nAfter launching the Cygwin terminal we can tune ~/.bashrc by running the following commands:\ncat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; ~/.bashrc PS1='\\[\\e[32m\\]\\u@\\h:\\W\u0026gt; \\[\\e[0m\\]' TERM=cygwin export PS1 export TERM EOF  Apply those changes to the current session by running:\nsource ~/.bashrc Install Ansible in Cygwin Next, run the following command to install Ansible (this will take some time):\npip3.6 install ansible Install kubectl in Cygwin If the Crunchy PostgreSQL Operator will be deployed to a Kubernetes cluster, we will require kubectl\nTo download kubectl run the following commands:\ncurl -LO https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/windows/amd64/kubectl.exe mv ./kubectl.exe /usr/local/bin/kubectl chmod +x /usr/local/bin/kubectl Install oc in Cygwin If the Crunchy PostgreSQL Operator will be deployed to a Kubernetes cluster, we will require oc\nTo download oc run the following commands:\ncurl -LO https://github.com/openshift/origin/releases/download/v3.11.0/openshift-origin-client-tools-v3.11.0-0cbc58b-windows.zip unzip openshift-origin-client-tools-v3.11.0-0cbc58b-windows.zip mv ./oc.exe /usr/local/bin/oc chmod +x /usr/local/bin/oc"
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/installation/installing-metrics/",
	"title": "Installing Metrics Stack",
	"tags": [],
	"description": "",
	"content": " Installing The following assumes the proper prerequisites are satisfied we can now install the PostgreSQL Operator.\nInstalling on Linux On a Linux host with Ansible installed we can run the following command to install the Metrics stack:\nThe following command should be run from the directory where the postgres-operator-playbooks project is located:\nansible-playbook -i /path/to/inventory main.yml --tags=install-metrics Installing on MacOS On a MacOS host with Ansible installed we can run the following command to install the Metrics stack:\nThe following command should be run from the directory where the postgres-operator-playbooks project is located:\nansible-playbook -i /path/to/inventory main.yml --tags=install-metrics Installing on Windows On a Windows host with a Cygwin terminal we can run the following commands to install the Metrics stack:\nFirst, run the following command to setup the ansible_python_interpreter for Cygwin:\nsed -i \u0026#39;s~/usr/bin/env python~/usr/bin/env.exe python3.6~g\u0026#39; /path/to/inventory The following command should be run from the directory where the postgres-operator-playbooks project is located:\nansible-playbook -i /path/to/inventory main.yml --tags=install-metrics Verifying the Installation This may take a few minutes to deploy. To check the status of the deployment run the following:\n# Kubernetes kubectl get deployments -n \u0026lt;NAMESPACE_NAME\u0026gt; kubectl get pods -n \u0026lt;NAMESPACE_NAME\u0026gt; # OpenShift oc get deployments -n \u0026lt;NAMESPACE_NAME\u0026gt; oc get pods -n \u0026lt;NAMESPACE_NAME\u0026gt; Verify Grafana In a separate terminal we need to setup a port forward to the Crunchy Grafana deployment to ensure connection can be made outside of the cluster:\n# If deployed to Kubernetes kubectl port-forward \u0026lt;GRAFANA_POD_NAME\u0026gt; -n \u0026lt;METRICS_NAMESPACE\u0026gt; 3000:3000 # If deployed to OpenShift oc port-forward \u0026lt;GRAFANA_POD_NAME\u0026gt; -n \u0026lt;METRICS_NAMESPACE\u0026gt; 3000:3000 In a browser navigate to https://127.0.0.1:3000 to access the Grafana dashboard.\nVerify Prometheus In a separate terminal we need to setup a port forward to the Crunchy Prometheus deployment to ensure connection can be made outside of the cluster:\n# If deployed to Kubernetes kubectl port-forward \u0026lt;PROMETHEUS_POD_NAME\u0026gt; -n \u0026lt;METRICS_NAMESPACE\u0026gt; 9090:9090 # If deployed to OpenShift oc port-forward \u0026lt;PROMETHEUS_POD_NAME\u0026gt; -n \u0026lt;METRICS_NAMESPACE\u0026gt; 9090:9090 In a browser navigate to https://127.0.0.1:9090 to access the Prometheus dashboard.\n"
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/installation/installing-operator/",
	"title": "Installing PostgreSQL Operator",
	"tags": [],
	"description": "",
	"content": " Installing The following assumes the proper prerequisites are satisfied we can now install the PostgreSQL Operator.\nInstalling on Linux On a Linux host with Ansible installed we can run the following command to install the PostgreSQL Operator:\nThe following command should be run from the directory where the postgres-operator-playbooks project is located:\nansible-playbook -i /path/to/inventory main.yml --tags=install --ask-become-pass Installing on MacOS On a MacOS host with Ansible installed we can run the following command to install the PostgreSQL Operator.\nThe following command should be run from the directory where the postgres-operator-playbooks project is located:\nansible-playbook -i /path/to/inventory main.yml --tags=install --ask-become-pass Installing on Windows On a Windows host with a Cygwin terminal we can run the following commands to install the PostgreSQL Operator.\nFirst, run the following command to setup the ansible_python_interpreter for Cygwin:\nsed -i \u0026#39;s~/usr/bin/env python~/usr/bin/env.exe python3.6~g\u0026#39; /path/to/inventory The following command should be run from the directory where the postgres-operator-playbooks project is located:\nansible-playbook -i /path/to/inventory main.yml --tags=install Verifying the Installation This may take a few minutes to deploy. To check the status of the deployment run the following:\n# Kubernetes kubectl get deployments -n \u0026lt;NAMESPACE_NAME\u0026gt; kubectl get pods -n \u0026lt;NAMESPACE_NAME\u0026gt; # OpenShift oc get deployments -n \u0026lt;NAMESPACE_NAME\u0026gt; oc get pods -n \u0026lt;NAMESPACE_NAME\u0026gt; Configure Environment Variables After the Crunchy PostgreSQL Operator has successfully been installed we will need to configure local environment variables before using the pgo client.\nLinux and MacOS To configure the environment variables used by pgo on a Linux or MacOS host, run the following command:\nNote: \u0026lt;PGO_NAMESPACE\u0026gt; should be replaced with the namespace the Crunchy PostgreSQL Operator was deployed to.\ncat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; ~/.bashrc export PGOUSER=\u0026#34;~/.pgo/\u0026lt;PGO_NAMESPACE\u0026gt;/pgouser\u0026#34; export PGO_CA_CERT=\u0026#34;~/.pgo/\u0026lt;PGO_NAMESPACE\u0026gt;/client.crt\u0026#34; export PGO_CLIENT_CERT=\u0026#34;~/.pgo/\u0026lt;PGO_NAMESPACE\u0026gt;/client.crt\u0026#34; export PGO_CLIENT_KEY=\u0026#34;~/.pgo/\u0026lt;PGO_NAMESPACE\u0026gt;/client.pem\u0026#34; export PGO_APISERVER_URL=https://127.0.0.1:8443 EOF Apply those changes to the current session by running:\nsource ~/.bashrc Windows (Cygwin) To configure the environment variables used by pgo on a Windows (Cygwin) host, run the following command:\nNote: \u0026lt;PGO_NAMESPACE\u0026gt; should be replaced with the namespace the Crunchy PostgreSQL Operator was deployed to.\ncat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; ~/.bashrc export PGOUSER=\u0026#34;$(cygpath -w ~/.pgo/\u0026lt;PGO_NAMESPACE\u0026gt;/pgouser)\u0026#34; export PGO_CA_CERT=\u0026#34;$(cygpath -w ~/.pgo/\u0026lt;PGO_NAMESPACE\u0026gt;/client.crt)\u0026#34; export PGO_CLIENT_CERT=\u0026#34;$(cygpath -w ~/.pgo/\u0026lt;PGO_NAMESPACE\u0026gt;/client.crt)\u0026#34; export PGO_CLIENT_KEY=\u0026#34;$(cygpath -w ~/.pgo/\u0026lt;PGO_NAMESPACE\u0026gt;/client.pem)\u0026#34; export PGO_APISERVER_URL=\u0026#34;https://127.0.0.1:8443\u0026#34; EOF Apply those changes to the current session by running:\nsource ~/.bashrc Verify pgo Connection In a separate terminal we need to setup a port forward to the Crunchy PostgreSQL Operator to ensure connection can be made outside of the cluster:\n# If deployed to Kubernetes kubectl port-forward \u0026lt;OPERATOR_POD_NAME\u0026gt; -n \u0026lt;OPERATOR_NAMESPACE\u0026gt; 8443:8443 # If deployed to OpenShift oc port-forward \u0026lt;OPERATOR_POD_NAME\u0026gt; -n \u0026lt;OPERATOR_NAMESPACE\u0026gt; 8443:8443 On a separate terminal verify the pgo can communicate with the Crunchy PostgreSQL Operator:\npgo version If the above command outputs versions of both the client and API server, the Crunchy PostgreSQL Operator has been installed successfully.\n"
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/uninstall/uninstalling-metrics/",
	"title": "Uninstalling Metrics Stack",
	"tags": [],
	"description": "",
	"content": " Uninstalling the Metrics Stack The following assumes the proper prerequisites are satisfied we can now deprovision the PostgreSQL Operator.\nFirst, it is recommended to use the playbooks tagged with the same version of the Metrics stack currently deployed.\nWith the correct playbooks acquired and prerequisites satisfied, simply run the following command:\nansible-playbook -i /path/to/inventory main.yml --tags=deprovision-metrics"
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/uninstall/uninstalling-operator/",
	"title": "Uninstalling PostgreSQL Operator",
	"tags": [],
	"description": "",
	"content": " Uninstalling PostgreSQL Operator The following assumes the proper prerequisites are satisfied we can now deprovision the PostgreSQL Operator.\nFirst, it is recommended to use the playbooks tagged with the same version of the PostgreSQL Operator currently deployed.\nWith the correct playbooks acquired and prerequisites satisfied, simply run the following command:\nansible-playbook -i /path/to/inventory main.yml --tags=deprovision Deleting pgo Client To remove the pgo client, simply run the following command:\nrm /usr/local/bin/pgo  "
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://crunchydata.github.io/postgres-operator-playbooks/latest/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]